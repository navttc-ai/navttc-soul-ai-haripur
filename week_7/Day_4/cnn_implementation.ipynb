{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition using a Convolutional Neural Network (CNN)\n",
    "\n",
    "This notebook provides a step-by-step guide to building, training, and testing a CNN to classify handwritten digits from the famous MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries\n",
    "\n",
    "First, we import all the required libraries. \n",
    "- **TensorFlow and Keras:** For building and training our neural network.\n",
    "- **MNIST dataset:** A built-in dataset in Keras containing 70,000 images of handwritten digits.\n",
    "- **Layers (Conv2D, MaxPooling2D, etc.):** The building blocks of our CNN.\n",
    "- **to_categorical:** A utility to convert integer labels into a one-hot encoded format.\n",
    "- **Matplotlib and NumPy:** For data visualization and numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess the Data\n",
    "\n",
    "Before we can train our model, we need to prepare the data. This involves several key steps:\n",
    "\n",
    "1.  **Load the dataset:** We load the MNIST dataset, which is conveniently split into training and testing sets.\n",
    "2.  **Reshape the images:** A CNN expects a 4D tensor as input: `(batch_size, height, width, channels)`. Since the MNIST images are grayscale, the number of channels is 1. We reshape our `(60000, 28, 28)` images to `(60000, 28, 28, 1)`.\n",
    "3.  **Normalize pixel values:** We scale the pixel values from their original range of `0-255` to a range of `0.0-1.0`. This helps the model learn more efficiently.\n",
    "4.  **One-hot encode labels:** We transform the integer labels (e.g., `5`) into a binary vector format (e.g., `[0,0,0,0,0,1,0,0,0,0]`). This is necessary for the `categorical_crossentropy` loss function we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28, 1)\n",
      "Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Save original test labels for later comparison\n",
    "y_test_original = y_test\n",
    "\n",
    "# Preprocessing for the CNN\n",
    "# 1. Reshape images to (28, 28, 1) - adding the '1' for grayscale channel\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# 2. Normalize pixel values from 0-255 to 0.0-1.0\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. One-hot encode the labels (e.g., 5 -> [0,0,0,0,0,1,0,0,0,0])\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the CNN Model\n",
    "\n",
    "Now we define the architecture of our Convolutional Neural Network using the Keras `Sequential` API.\n",
    "\n",
    "- **Conv2D:** These are the convolutional layers that apply filters to the image to learn features like edges, corners, and textures.\n",
    "- **MaxPooling2D:** This layer downsamples the feature maps, reducing their dimensions and making the model more robust to variations in the position of features.\n",
    "- **Flatten:** This layer converts the 2D feature maps from the convolutional layers into a 1D vector, preparing the data for the fully connected layers.\n",
    "- **Dense:** These are standard fully connected neural network layers.\n",
    "- **Dropout:** A regularization technique that randomly sets a fraction of input units to 0 during training to prevent overfitting.\n",
    "- **Softmax (Output Layer):** The final layer has 10 neurons (one for each digit from 0 to 9) and uses the `softmax` activation function to output a probability distribution over the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # First convolutional layer\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the 2D maps to 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected dense layer\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5), # Dropout for regularization\n",
    "    \n",
    "    # Output layer (10 classes, softmax for probabilities)\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compile and Train the Model\n",
    "\n",
    "Before training, we need to configure the learning process using `model.compile()`.\n",
    "\n",
    "- **optimizer='adam'**: Adam is an efficient optimization algorithm that adjusts the learning rate during training.\n",
    "- **loss='categorical_crossentropy'**: This loss function is suitable for multi-class classification problems where labels are one-hot encoded.\n",
    "- **metrics=['accuracy']**: We monitor the classification accuracy during training and evaluation.\n",
    "\n",
    "Then, we train the model using `model.fit()`, passing it the training data, batch size, number of epochs, and a validation split to monitor performance on a subset of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "# Train for 5 epochs (for a quick example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 14s 30ms/step - loss: 0.3109 - accuracy: 0.9054 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1005 - accuracy: 0.9701 - val_loss: 0.0418 - val_accuracy: 0.9882\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.0730 - accuracy: 0.9786 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 12s 28ms/step - loss: 0.0591 - accuracy: 0.9824 - val_loss: 0.0413 - val_accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "--- Model Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=128, \n",
    "          epochs=5, \n",
    "          validation_split=0.1)\n",
    "print(\"--- Model Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model\n",
    "\n",
    "After training is complete, we evaluate the model's performance on the unseen test data. This gives us a good indication of how well our model generalizes to new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.026710160076618195\n",
      "Test accuracy: 0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'\\nTest loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Define a Visualization Function\n",
    "\n",
    "To make our predictions more intuitive, we'll create a simple helper function to display a digit's image along with its true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(image, true_label):\n",
    "    \"\"\"\n",
    "    Displays a single MNIST digit and its true label.\n",
    "    \"\"\"\n",
    "    # The image is (28, 28, 1), plt.imshow needs (28, 28)\n",
    "    image = image.reshape(28, 28)\n",
    "    \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'True Label: {true_label}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Test the Model on a Single Image\n",
    "\n",
    "Finally, let's pick a single image from our test set and see what the model predicts.\n",
    "\n",
    "1.  **Select an image:** We choose an image and its corresponding original label.\n",
    "2.  **Visualize:** We use our `display_digit` function to see the image.\n",
    "3.  **Prepare for Prediction:** The `model.predict()` method expects a batch of images. We need to add an extra dimension to our single image `(28, 28, 1)` to make it a batch of one: `(1, 28, 28, 1)`.\n",
    "4.  **Make Prediction:** We call `model.predict()`.\n",
    "5.  **Interpret Result:** The output is an array of 10 probabilities. We use `np.argmax()` to find the index (the digit) with the highest probability and compare it to the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick an image from the test set, e.g., the 10th image (index 9)\n",
    "instance_index = 9\n",
    "test_image = x_test[instance_index]\n",
    "true_label = y_test_original[instance_index] # Get the original number label\n",
    "\n",
    "# Step 7a: Visualize the digit\n",
    "print(f\"\\n--- Visualizing Test Image #{instance_index} ---\")\n",
    "display_digit(test_image, true_label)\n",
    "\n",
    "# Step 7b: Prepare the image for prediction\n",
    "# The model.predict() method expects a *batch* of images.\n",
    "# Our image is (28, 28, 1), we need to make it (1, 28, 28, 1)\n",
    "image_for_prediction = np.expand_dims(test_image, axis=0)\n",
    "print(f\"Original image shape: {test_image.shape}\")\n",
    "print(f\"Shape for prediction: {image_for_prediction.shape}\")\n",
    "\n",
    "# Step 7c: Make the prediction\n",
    "prediction = model.predict(image_for_prediction)\n",
    "\n",
    "# The 'prediction' is an array of 10 probabilities\n",
    "# We find the index with the highest probability\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Step 7d: Show the result\n",
    "print(\"\\n--- Prediction Result ---\")\n",
    "print(f\"Model's Prediction: {predicted_class}\")\n",
    "print(f\"True Label:           {true_label}\")\n",
    "\n",
    "if predicted_class == true_label:\n",
    "    print(\"Result: Correct! ✅\")\n",
    "else:\n",
    "    print(\"Result: Incorrect. ❌\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
