{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746002f4",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Introduction to Multiclass Logistic Regression for AI Beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf2b35",
   "metadata": {},
   "source": [
    "Welcome to this 2-hour session on Multiclass Logistic Regression! This is a powerful and popular machine learning algorithm used to classify data into **three or more** categories. \n",
    "\n",
    "### What is Multiclass Logistic Regression?\n",
    "\n",
    "It's a classification algorithm that predicts the probability of something belonging to one of several different classes. Think of it as an extension of *Binary* Logistic Regression, which can only handle two classes (like 'Yes' or 'No'). \n",
    "\n",
    "For example, we can use it to:\n",
    "*   Classify news articles into topics like \"Sports,\" \"Politics,\" or \"Technology.\"\n",
    "*   Identify the species of a flower from its measurements.\n",
    "*   Analyze sentiment as \"Positive,\" \"Negative,\" or \"Neutral.\"\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives for Today:\n",
    "\n",
    "By the end of this session, you will understand:\n",
    "1.  **What** multiclass classification is and why it's useful.\n",
    "2.  The **One-vs-Rest (OvR)** strategy for handling multiple classes.\n",
    "3.  The **Multinomial (Softmax) Regression** approach.\n",
    "4.  How to **implement** these methods in Python using the `scikit-learn` library.\n",
    "5.  How to **evaluate** your classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f7c62",
   "metadata": {},
   "source": [
    "## Topic 1: The One-vs-Rest (OvR) Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bf501",
   "metadata": {},
   "source": [
    "ðŸ“„ **Explanation**\n",
    "\n",
    "The One-vs-Rest (OvR) method is a clever way to use a simple binary classifier (which only knows how to separate two groups) to solve a multiclass problem.\n",
    "\n",
    "**The Logic is simple:** Break down one big multiclass problem into several smaller binary problems.\n",
    "\n",
    "Imagine you have 3 classes: **Cat, Dog, Bird**.\n",
    "\n",
    "OvR will train **3 separate models**:\n",
    "1.  **Model 1:** Learns to distinguish **Cat** (`Class 1`) vs. **'Not Cat'** (`Rest`: Dog, Bird).\n",
    "2.  **Model 2:** Learns to distinguish **Dog** (`Class 2`) vs. **'Not Dog'** (`Rest`: Cat, Bird).\n",
    "3.  **Model 3:** Learns to distinguish **Bird** (`Class 3`) vs. **'Not Bird'** (`Rest`: Cat, Dog).\n",
    "\n",
    "When you have a new animal to classify, you show it to all three models. Each model gives a probability score. The model that gives the highest score wins, and its class is assigned as the final prediction! \n",
    "\n",
    "ðŸ’¡ **Fun Fact:** This is a very intuitive and common strategy. Because it trains independent models, it can sometimes be slower if you have a huge number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9edf5",
   "metadata": {},
   "source": [
    "### ðŸ§  Practice Task 1\n",
    "\n",
    "You are building a model to classify handwritten digits from 0 to 9. If you use the One-vs-Rest (OvR) strategy, how many binary models will you need to train? What would the first model (for digit '0') be trained to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c23e0",
   "metadata": {},
   "source": [
    "## Topic 2: Multinomial Logistic Regression (Softmax Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fc21a",
   "metadata": {},
   "source": [
    "ðŸ“„ **Explanation**\n",
    "\n",
    "This is a more direct and often more effective approach. Instead of training multiple independent models, Multinomial or **Softmax Regression** trains a **single, unified model** that handles all classes at once.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1.  **Calculate Scores (Logits):** For a new input, the model first calculates a raw score for each class. This score is called a 'logit'.\n",
    "2.  **Apply the Softmax Function:** The magic happens here! The **Softmax function** takes all the raw scores and squashes them into a set of probabilities that add up to 1.0 (or 100%).\n",
    "\n",
    "This is powerful because the classes are considered together. Increasing the probability of one class will automatically decrease the probability of the others, which makes sense because an object can usually only belong to one class at a time.\n",
    "\n",
    "#### Numerical Example Walkthrough\n",
    "Imagine our model gives these scores (logits) for a new animal: `Cat = 1.5`, `Dog = 7.0`, `Bird = -1.4`.\n",
    "\n",
    "The Softmax function turns these into probabilities:\n",
    "*   P(Cat) â‰ˆ 0.4%\n",
    "*   P(Dog) â‰ˆ 99.6%\n",
    "*   P(Bird) â‰ˆ 0.02%\n",
    "\n",
    "Since 'Dog' has the highest probability, the model's final prediction is **Dog**. âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a3370",
   "metadata": {},
   "source": [
    "### ðŸ§  Practice Task 2\n",
    "\n",
    "A model gives you the following logits for three news article categories: `Sports = 3.0`, `Politics = 0.5`, `Technology = 1.5`.\n",
    "\n",
    "Without doing the full calculation, which category will the Softmax function give the highest probability to? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93587f",
   "metadata": {},
   "source": [
    "## Topic 3: Python Implementation with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e15a88",
   "metadata": {},
   "source": [
    "ðŸ“„ **Explanation**\n",
    "\n",
    "Enough theory! Let's build some models. We will use the famous **Iris dataset**, which contains measurements for 3 different species of iris flowers. Our goal is to train a model that can predict the species based on these measurements.\n",
    "\n",
    "We will build **both** an OvR and a Softmax model to see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3805fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split successfully!\n",
      "Shape of training data: (105, 4)\n",
      "Shape of testing data: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # The features (flower measurements)\n",
    "y = iris.target # The labels (flower species: 0, 1, or 2)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "# We train the model on the training set and test its performance on the unseen testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Data loaded and split successfully!\")\n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of testing data:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77692374",
   "metadata": {},
   "source": [
    "ðŸ’» **Code Example: Training the One-vs-Rest (OvR) Model**\n",
    "\n",
    "In `scikit-learn`, we just need to set `multi_class='ovr'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f0d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- One-vs-Rest (OvR) Model Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.85      0.92        13\n",
      "   virginica       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qasim\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create and train the OvR model\n",
    "# We set max_iter=200 to ensure the model has enough iterations to find the best solution.\n",
    "ovr_model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "ovr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "ovr_pred = ovr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"--- One-vs-Rest (OvR) Model Evaluation ---\")\n",
    "print(classification_report(y_test, ovr_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9354e",
   "metadata": {},
   "source": [
    "ðŸ’» **Code Example: Training the Multinomial (Softmax) Model**\n",
    "\n",
    "Now, let's train the Softmax model by setting `multi_class='multinomial'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a72cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Softmax (Multinomial) Model Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qasim\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Softmax model\n",
    "# The 'lbfgs' solver is a good default for multinomial problems.\n",
    "softmax_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200)\n",
    "softmax_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "softmax_pred = softmax_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"--- Softmax (Multinomial) Model Evaluation ---\")\n",
    "print(classification_report(y_test, softmax_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2fb3c",
   "metadata": {},
   "source": [
    "You'll notice both models perform perfectly on this simple dataset! In more complex, real-world scenarios, one might perform better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8fa41",
   "metadata": {},
   "source": [
    "ðŸ’» **Code Example: Predicting Probabilities for a New Flower**\n",
    "\n",
    "Let's see what our Softmax model predicts for a new flower with specific measurements. We can also see the probabilities for each class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d10879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for new flower (Setosa, Versicolor, Virginica): [[9.73074237e-01 2.69256274e-02 1.35872683e-07]]\n",
      "Predicted class: setosa\n"
     ]
    }
   ],
   "source": [
    "# A new flower with measurements [sepal length, sepal width, petal length, petal width]\n",
    "# These measurements are typical for a 'setosa' flower.\n",
    "new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "# Predict the probabilities for each class\n",
    "softmax_probs = softmax_model.predict_proba(new_flower)\n",
    "\n",
    "# Get the final predicted class name\n",
    "predicted_class_index = softmax_model.predict(new_flower)[0]\n",
    "predicted_class_name = iris.target_names[predicted_class_index]\n",
    "\n",
    "print(f\"Probabilities for new flower (Setosa, Versicolor, Virginica): {softmax_probs}\")\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e3594",
   "metadata": {},
   "source": [
    "### ðŸ§  Practice Task 3\n",
    "\n",
    "ðŸ§ª **Time to experiment!**\n",
    "1. Create a new code cell below.\n",
    "2. Define a new flower called `my_flower`. A typical 'virginica' flower might have measurements like `[[6.7, 3.0, 5.2, 2.3]]`.\n",
    "3. Use the `softmax_model.predict()` and `softmax_model.predict_proba()` functions on your `my_flower`.\n",
    "4. Print the results. Did the model correctly classify it as 'virginica'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa899dad",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Final Revision Assignment ðŸŽ‰\n",
    "\n",
    "Let's test your knowledge! Try to complete these tasks to solidify what you've learned. These are great for home practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32759594",
   "metadata": {},
   "source": [
    "#### **Task 1: Multiple Choice**\n",
    "Which function is used in Multinomial Logistic Regression to convert model scores into a probability distribution across multiple classes?\n",
    "A. Sigmoid\n",
    "B. ReLU\n",
    "C. Tanh\n",
    "D. Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffe323",
   "metadata": {},
   "source": [
    "#### **Task 2: Multiple Choice**\n",
    "In the One-vs-Rest (OvR) strategy for a problem with 5 classes, how many binary classifiers are trained?\n",
    "A. 1\n",
    "B. 5\n",
    "C. 10\n",
    "D. 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584d52b",
   "metadata": {},
   "source": [
    "#### **Task 3: Short Question**\n",
    "Briefly explain the main difference between how the One-vs-Rest (OvR) and Softmax Regression approaches handle a multiclass problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821fc1f",
   "metadata": {},
   "source": [
    "#### **Task 4: Calculation Problem**\n",
    "A multiclass logistic regression model outputs the following logits for three classes: `Class A = 2.0`, `Class B = 1.0`, `Class C = -1.0`.\n",
    "\n",
    "Calculate the probability for **Class A** using the Softmax formula. (You'll need a calculator for e^x).\n",
    "\n",
    "*   e^2.0 â‰ˆ 7.39\n",
    "*   e^1.0 â‰ˆ 2.72\n",
    "*   e^-1.0 â‰ˆ 0.37\n",
    "\n",
    "**Formula:** P(A) = e^(score_A) / (e^(score_A) + e^(score_B) + e^(score_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c21160",
   "metadata": {},
   "source": [
    "#### **Task 5: Coding Challenge!**\n",
    "\n",
    "Let's work with a new dataset: handwritten digits! Your task is to train a model to recognize digits from 0-9.\n",
    "\n",
    "In a new code cell, follow these steps:\n",
    "1. **Import** `load_digits` from `sklearn.datasets`.\n",
    "2. **Load** the dataset: `digits = load_digits()`.\n",
    "3. **Split** the data (`digits.data`, `digits.target`) into training and testing sets.\n",
    "4. **Train** a `LogisticRegression` model using the **Softmax** (`multinomial`) approach.\n",
    "5. **Evaluate** your model using the `classification_report`. How well did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccea454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the Coding Challenge goes here!\n",
    "# from sklearn.datasets import load_digits\n",
    "\n",
    "# Step 1: Load the data\n",
    "\n",
    "\n",
    "# Step 2: Split the data\n",
    "\n",
    "\n",
    "# Step 3: Train the Softmax model\n",
    "\n",
    "\n",
    "# Step 4: Evaluate and print the report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d277a",
   "metadata": {},
   "source": [
    "### âœ… Well done! \n",
    "You have completed the introduction to Multiclass Logistic Regression. You are now equipped with the knowledge to tackle multiclass classification problems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
